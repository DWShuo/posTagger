{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import conllu\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global dictionary to hold prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTPROB = {} #probability of starting with this pos\n",
    "TRANSPROB = {} #probability of transitioning from pos X -> Y\n",
    "EMISSIONPROB = {} #probability of word coming emitting from particular pos\n",
    "TAGPROB = {} #probabililty of seeing this tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unkown words must incur a penalty such that know words should always be prefered given that it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNKOWN_PENALTY = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calculate list of tags and the probaility of this tag occuring indpendently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate list of tags '''\n",
    "def calcTagProb(dataset):\n",
    "    tagDict = {} #dictonary record number of upostag seen\n",
    "    tagTotal = 0\n",
    "    '''if upostag exists increment else create new and set to 1'''\n",
    "    for each in dataset:\n",
    "        for i in range(len(each) - 1):\n",
    "            tag = each[i]['upostag'] #get upostag for word\n",
    "            if tag in tagDict:\n",
    "                tagDict[tag] = tagDict.get(tag) + 1\n",
    "            else:\n",
    "                tagDict[tag] = 1\n",
    "            tagTotal += 1\n",
    "    '''Convert dict in to list of tags'''\n",
    "    for each in tagDict:\n",
    "        prob = (tagDict[each]/tagTotal)\n",
    "        TAGPROB[each] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calculate probability that a particular POS is the starting tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate starting probabilities '''\n",
    "def calcStartProb(dataset):\n",
    "    startDict = {} #dictonary record number of upostag seen\n",
    "    startTotal = 0 #count how many upostag seen from dataset\n",
    "    '''if upostag exists increment else create new and set to 1'''\n",
    "    for each in dataset:\n",
    "        tag = each[0]['upostag'] #get upostag for word\n",
    "        startTotal += 1 #increment total counter\n",
    "        if tag in startDict:\n",
    "            startDict[tag] = startDict.get(tag) + 1\n",
    "        else:\n",
    "            startDict[tag] = 1\n",
    "    '''Calculate start probability and store in global dict'''\n",
    "    for each in startDict:\n",
    "        prob = (startDict[each]/startTotal)\n",
    "        STARTPROB[each] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calculates probability of POS X -> POS Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate transitional probaility '''\n",
    "def calcTransProb(dataset):\n",
    "    transDict = {} #dictonary record number of transations from x->y\n",
    "    transTotal = 0 #count how many transitions there are\n",
    "    '''itr through sentence and record each instance of POS x->y '''\n",
    "    for each in dataset:\n",
    "        for i in range(len(each) - 1):\n",
    "            transTotal += 1 #increment total counter\n",
    "            tagX = each[i]['upostag']\n",
    "            tagY = each[i+1]['upostag']\n",
    "            transition = tagX + \"_\" + tagY #append x->y POS transition used as dict key\n",
    "            '''if transition exists increment else create new and set to 1'''\n",
    "            if transition in transDict:\n",
    "                transDict[transition] = transDict.get(transition) + 1\n",
    "            else:\n",
    "                transDict[transition] = 1\n",
    "    '''Calculate transition probability and store in global dict'''\n",
    "    for each in transDict:\n",
    "        prob = (transDict[each]/transTotal)\n",
    "        TRANSPROB[each] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the probability that a particular word will be emitted from given POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate emission probaility '''\n",
    "def calcEmissionProb(dataset):\n",
    "    emissionDict = {}\n",
    "    for each in dataset:\n",
    "        for i in range(len(each)):\n",
    "            tag = each[i]['upostag']\n",
    "            word = each[i]['form'].lower()\n",
    "            normal = each[i]['lemma'].lower()\n",
    "            ''' Logic handling nested dict '''\n",
    "            #if tag not in dict then no word has been counted for that tag\n",
    "            if tag not in emissionDict: \n",
    "                emissionDict[tag] = {}\n",
    "                emissionDict[tag][word] = 1\n",
    "                emissionDict[tag][normal] = 1\n",
    "            #if tag is in dict check if word is counted; if not create new, else increment count\n",
    "            if tag in emissionDict:\n",
    "                if word not in emissionDict[tag]:\n",
    "                    emissionDict[tag][word] = 1\n",
    "                else:\n",
    "                    emissionDict[tag][word] = emissionDict[tag][word] + 1\n",
    "                if normal not in emissionDict[tag]:\n",
    "                    emissionDict[tag][normal] = 1\n",
    "                else:\n",
    "                    emissionDict[tag][word] = emissionDict[tag][word] + 1\n",
    "    ''' calculate emission probability '''\n",
    "    for upostag in emissionDict:\n",
    "        tempTotal = 0\n",
    "        EMISSIONPROB[upostag] = {}\n",
    "        #calculate total words for current upostag\n",
    "        for each in emissionDict[upostag]:\n",
    "            tempTotal += emissionDict[upostag][each]\n",
    "        #calculate probability\n",
    "        for each in emissionDict[upostag]:\n",
    "            EMISSIONPROB[upostag][each] = emissionDict[upostag][each] / tempTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following 2 functions deal with log transform for probability multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safeLog(x):\n",
    "    # The probability of any possible event is a negative number, 0 is used to represent\n",
    "    # impossible\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safeMultiply(x, y):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif y == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very naive stemming technique, remove 1 char at a time from back ,do samething from front then return a list of each char removed and brute force to see if variation exits.\n",
    "sort list so that longest words appear in the front, so we dont automaticlly assume the word is a DET like A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleStemming(word):\n",
    "    morphList = []\n",
    "    for i in range(len(word)):\n",
    "        morphList.append(word[:i*-1])\n",
    "        morphList.append(word[i:])\n",
    "    morphList = list(dict.fromkeys(morphList)) #removes duplicates from list\n",
    "    morphList.sort(key=len, reverse=True) #sort by word length\n",
    "    morphList = morphList[1:-1] #remove front and back\n",
    "    morphList = [i for i in morphList if len(i) > 2]\n",
    "    return morphList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Hidden markov model\n",
    "Strategy for dealing with unknown words\n",
    "1. first we create a list of words by stripping away a letter at a time, with the intention  that if we encounter a word such as resourcefulness we can strip away until we get a normalized version of the word in this case resourceful.\n",
    "2. If the above attempt fails as a last resort we ignore emission proability and assgin the number 0.0001 as the emission probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Implementation of Hidden Markov model '''\n",
    "def viterbiAlgo(sentence, tags):\n",
    "    ''' init tables and array used in dynamic programming '''\n",
    "    sentenceLen = len(sentence)\n",
    "    states = np.arange(len(TAGPROB))\n",
    "    table = np.zeros( (len(TAGPROB), sentenceLen) )\n",
    "    pred = []\n",
    "    ''' Starting probability '''\n",
    "    '''\n",
    "        Since our table is an indexable list, and our probability is a un-indexable dict\n",
    "        we need a external counter variable(eachCounter)\n",
    "    '''\n",
    "    eachCounter = 0\n",
    "    print(\"[ \" +sentence[0] + \" ] \" + tags[0])#DEBUG\n",
    "    for each in TAGPROB:\n",
    "        lastResort = True\n",
    "        try:\n",
    "            table[eachCounter,0] = safeMultiply(safeLog(STARTPROB[each]), safeLog(EMISSIONPROB[each][sentence[0]]))\n",
    "            lastResort = False\n",
    "        except:\n",
    "            morphList = simpleStemming(sentence[0])\n",
    "            for wordMorph in morphList:\n",
    "                try:\n",
    "                    table[eachCounter,0] = safeMultiply(safeLog(STARTPROB[each]), safeLog(EMISSIONPROB[each][wordMorph] * UNKOWN_PENALTY * TAGPROB[each]))\n",
    "                    lastResort = False\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        if lastResort == True:\n",
    "            try:\n",
    "                table[eachCounter,0] = safeMultiply(safeLog(STARTPROB[each]), safeLog(0.00001 * UNKOWN_PENALTY * TAGPROB[each]))\n",
    "            except:\n",
    "                logProb = 0\n",
    "                lastResort = False\n",
    "        print(each + \"\\t\" + str(table[eachCounter, 0]))#DEBUG\n",
    "        eachCounter += 1\n",
    "    print(\"----\") #DEBUG\n",
    "\n",
    "    ''' Dynamic programming '''\n",
    "    for i in range(1, sentenceLen): #for each word fill in probability\n",
    "        print(\"[ \" +sentence[i] + \" ] \" + tags[i])#DEBUG\n",
    "        state1Row = 0\n",
    "        for state1 in TAGPROB:\n",
    "            bestProb = 0\n",
    "            state2Row = 0\n",
    "            for state2 in TAGPROB:\n",
    "                tranState = state2 + \"_\" + state1\n",
    "                logProb = 0\n",
    "                lastResort = True\n",
    "                try:\n",
    "                    logProb = safeMultiply(safeMultiply(table[state2Row, i-1], safeLog(TRANSPROB[tranState])), safeLog(EMISSIONPROB[state1][sentence[i]]))\n",
    "                    lastResort = False\n",
    "                except Exception as e:\n",
    "                    morphList = simpleStemming(sentence[i])\n",
    "                    for wordMorph in morphList:\n",
    "                        try:\n",
    "                            logProb = safeMultiply(safeMultiply(table[state2Row, i-1], safeLog(TRANSPROB[tranState])), safeLog(EMISSIONPROB[state1][wordMorph] * UNKOWN_PENALTY * TAGPROB[state2]))\n",
    "                            lastResort = False\n",
    "                            break\n",
    "                        except:\n",
    "                            continue\n",
    "                if lastResort == True:\n",
    "                    try:\n",
    "                        emissionHardCode = 0.00001\n",
    "                        if state2 == \"VERB\" and sentence[i][-2:] == \"ed\":\n",
    "                            emissionHardCode = 0.80\n",
    "                        logProb = safeMultiply(safeMultiply(table[state2Row, i-1], safeLog(TRANSPROB[tranState])), safeLog(0.00001 * UNKOWN_PENALTY * TAGPROB[state2]))\n",
    "                    except:\n",
    "                        logProb = 0\n",
    "                    lastResort = False\n",
    "                if not logProb == 0:\n",
    "                    if (bestProb == 0) or (logProb > bestProb):\n",
    "                        bestProb = logProb\n",
    "                state2Row += 1\n",
    "            table[state1Row, i] = bestProb\n",
    "            print(state1 + \"\\t\" + str(table[state1Row, i]))#DEBUG\n",
    "            state1Row += 1\n",
    "        print(\"----\")#DEBUG\n",
    "\n",
    "    for i in range(sentenceLen):\n",
    "        possibleTags = table[:,i]\n",
    "        maxProb = np.max(possibleTags[np.nonzero(possibleTags)])\n",
    "        idx = possibleTags.tolist().index(maxProb)\n",
    "        tagList = list(TAGPROB.keys())\n",
    "        pred.append(tagList[idx])\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ''' handle command line arguments '''\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: python hmm.py --<train/test> <file>\")\n",
    "        sys.exit()\n",
    "    function = sys.argv[1] #train or test data\n",
    "    path = sys.argv[2] #path to data file\n",
    "    #open conllu file for reading\n",
    "    data_file = open(path, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    ''' we can either train from data, or test our result from data '''\n",
    "    if function == \"--train\":\n",
    "        dataset = []\n",
    "        #store each tokenlist in dataset list\n",
    "        for tokenlist in conllu.parse_incr(data_file):\n",
    "            dataset.append(tokenlist)\n",
    "        ''' Calculate relevent probailities '''\n",
    "        calcTagProb(dataset)\n",
    "        calcStartProb(dataset)\n",
    "        calcTransProb(dataset)\n",
    "        calcEmissionProb(dataset)\n",
    "\n",
    "        #store DICT in pickle file\n",
    "        with open('tagprob.pickle', 'wb') as tagOut:\n",
    "            pickle.dump(TAGPROB, tagOut)\n",
    "        with open('startprob.pickle', 'wb') as startOut:\n",
    "            pickle.dump(STARTPROB, startOut)\n",
    "        with open('transprob.pickle', 'wb') as transOut:\n",
    "            pickle.dump(TRANSPROB, transOut)\n",
    "        with open('emissionprob.pickle', 'wb') as emissionOut:\n",
    "            pickle.dump(EMISSIONPROB, emissionOut)\n",
    "\n",
    "    ''' we can either train from data, or test our result from data '''\n",
    "    if function == \"--test\":\n",
    "        ''' load in pickled probability dictonary '''\n",
    "        #list of possible tags\n",
    "        tagIn = open('tagprob.pickle','rb')\n",
    "        TAGPROB = pickle.load(tagIn)\n",
    "        #emission probability\n",
    "        emissionIn = open('emissionprob.pickle','rb')\n",
    "        EMISSIONPROB = pickle.load(emissionIn)\n",
    "        #starting probability\n",
    "        startIn = open('startprob.pickle','rb')\n",
    "        STARTPROB = pickle.load(startIn)\n",
    "        #transisition probability\n",
    "        transIn = open('transprob.pickle','rb')\n",
    "        TRANSPROB = pickle.load(transIn)\n",
    "\n",
    "        totalTags = 0\n",
    "        correctTags = 0\n",
    "        counter = 1\n",
    "        for tokenlist in conllu.parse_incr(data_file):\n",
    "            #if counter != 55: #<======== EDIT HERE\n",
    "            #    counter += 1\n",
    "            #    continue\n",
    "            wordList = []\n",
    "            tagList = []\n",
    "            for word in tokenlist:\n",
    "                wordList.append(word['form'].lower())\n",
    "                tagList.append(word['upostag'])\n",
    "            print(counter)\n",
    "            print(wordList)\n",
    "            pred = viterbiAlgo(wordList, tagList)\n",
    "            print(tagList)\n",
    "            print(pred)\n",
    "            for i in range(len(pred)):\n",
    "                totalTags += 1\n",
    "                if pred[i] == tagList[i]:\n",
    "                    correctTags += 1\n",
    "            #break\n",
    "            counter += 1\n",
    "        print(correctTags/totalTags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
